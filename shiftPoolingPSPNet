from keras.models import Model
from keras import backend as K
from keras.layers import Input, merge, Conv2D, ZeroPadding2D, UpSampling2D, Dense, concatenate, Conv2DTranspose,SeparableConv2D,ReLU
from keras.layers.pooling import MaxPooling2D, GlobalAveragePooling2D,AveragePooling2D
from keras.layers.core import Dense, Dropout, Activation

def pool_block( feats , pool_factor,depth=512 ):


	if IMAGE_ORDERING == 'channels_first':
		h = K.int_shape( feats )[2]
		w = K.int_shape( feats )[3]
	elif IMAGE_ORDERING == 'channels_last':
		h = K.int_shape( feats )[1]
		w = K.int_shape( feats )[2]

	# strides = [18,18],[9,9],[6,6],[3,3]
	pool_size = strides = [int(np.round( float(h) /  pool_factor)), int(np.round(  float(w )/  pool_factor))]
 
	# ���в�ͬ�̶ȵ�ƽ��
	x = AveragePooling2D(pool_size , data_format=IMAGE_ORDERING , strides=strides, padding='same')( feats )
	
	# ���о��
	x = Conv2D(depth, (1 ,1 ), data_format=IMAGE_ORDERING , padding='same' , use_bias=False )( x )
	x = BatchNormalization()(x)
	x = Activation('relu' )(x)

	x =tf.image.resize_images(x,feats.shape[1:3])

	return x
def shiftLeftPoolBlock( feats , pool_factor,depth ):
    if IMAGE_ORDERING == 'channels_first':
        h = K.int_shape( feats )[2]
        w = K.int_shape( feats )[3]
    elif IMAGE_ORDERING == 'channels_last':
        h = K.int_shape( feats )[1]
        w = K.int_shape( feats )[2]
    pool_size = strides = [int(np.round( float(h) /  pool_factor)), int(np.round(  float(w )/  pool_factor))]
    #padding half of pool_size
    padSize=int(pool_size[0]/2)
    pad=tf.pad(feats,[[0,0],[0,0],[padSize,padSize],[0,0]],"SYMMETRIC")   
    x= MaxPooling2D(pool_size , data_format=IMAGE_ORDERING , strides=strides, padding='same')( pad )
    x = Conv2D(depth, (1 ,1 ), data_format=IMAGE_ORDERING , padding='same' , use_bias=False )( x )
    x = BatchNormalization()(x)
    x = Activation('relu' )(x)
    #上采样到padding的大小
    #x =UpSampling2D(int(pool_size[0]))(x)
    x=tf.image.resize_images(x,pad.shape[1:3])
    #将pad裁剪成原feat的大小
    x=tf.slice(x,[0,0,padSize,0],[-1,h,w,-1])
    return x

def shiftTopPoolBlock( feats , pool_factor,depth ):
    if IMAGE_ORDERING == 'channels_first':
        h = K.int_shape( feats )[2]
        w = K.int_shape( feats )[3]
    elif IMAGE_ORDERING == 'channels_last':
        h = K.int_shape( feats )[1]
        w = K.int_shape( feats )[2]
    pool_size = strides = [int(np.round( float(h) /  pool_factor)), int(np.round(  float(w )/  pool_factor))]
    #padding half of pool_size
    padSize=int(pool_size[0]/2)
    pad=tf.pad(feats,[[0,0],[padSize,padSize],[0,0],[0,0]],"SYMMETRIC")   
    x= MaxPooling2D(pool_size , data_format=IMAGE_ORDERING , strides=strides, padding='same')( pad )
    x = Conv2D(depth, (1 ,1 ), data_format=IMAGE_ORDERING , padding='same' , use_bias=False )( x )
    x = BatchNormalization()(x)
    x = Activation('relu' )(x)
    #上采样到padding的大小
    #x =UpSampling2D(int(pool_size[0]))(x)
    x=tf.image.resize_images(x,pad.shape[1:3])
    #将pad裁剪成原feat的大小
    x=tf.slice(x,[0,padSize,0,0],[-1,h,w,-1])
    return x

def shiftTopLeftPoolBlock( feats , pool_factor,depth ):
    if IMAGE_ORDERING == 'channels_first':
        h = K.int_shape( feats )[2]
        w = K.int_shape( feats )[3]
    elif IMAGE_ORDERING == 'channels_last':
        h = K.int_shape( feats )[1]
        w = K.int_shape( feats )[2]
    pool_size = strides = [int(np.round( float(h) /  pool_factor)), int(np.round(  float(w )/  pool_factor))]
    #padding half of pool_size
    padSize=int(pool_size[0]/2)
    pad=tf.pad(feats,[[0,0],[padSize,padSize],[padSize,padSize],[0,0]],"SYMMETRIC")   
    x= MaxPooling2D(pool_size , data_format=IMAGE_ORDERING , strides=strides, padding='same')( pad )
    x = Conv2D(depth, (1 ,1 ), data_format=IMAGE_ORDERING , padding='same' , use_bias=False )( x )
    x = BatchNormalization()(x)
    x = Activation('relu' )(x)
    #上采样到padding的大小
    #x =UpSampling2D(int(pool_size[0]))(x)
    x=tf.image.resize_images(x,pad.shape[1:3])
    #将pad裁剪成原feat的大小
    x=tf.slice(x,[0,padSize,padSize,0],[-1,h,w,-1])
    return x

def shiftPooling_PSPNet(image,classNum):
    #net=resnet2.resnet_v2_101(image,classNum)
    logits, end_points = resnet2.resnet_v2_101(image,classNum)
    #high_level_features = end_points['resnet_v2_101/block4'] #�߼�����
    high_level_features=end_points['resnet_v2_101/block2/unit_4/bottleneck_v2/conv1']#���һ��64λ��
    #low_level_features = end_points['resnet_v2_101/block1/unit_3/bottleneck_v2/conv1']# �ͼ�����
    

    # �Ը߼��������в�ͬ�̶ȵĳػ�
   
    pool_outs = [high_level_features ]

    p =1
    pooled = pool_block(  high_level_features , p ,32 )
    pool_outs.append( pooled )
   
   
    for p in [2,4,6]:
        #original pool
        raw = pool_block(  high_level_features , p ,32 )
        

        #shiftLeft pool    
        left = shiftLeftPoolBlock(  high_level_features , p  ,32 )
        

        #shiftTop pool    
        top = shiftTopPoolBlock(  high_level_features , p ,32  )
       
    
        #shiftTopLeft pool    
        topleft = shiftTopLeftPoolBlock(  high_level_features , p,32  )
        
        o = Concatenate( axis=3)([raw,left,top,topleft] )
        o = Conv2D(32, (1,1), data_format=IMAGE_ORDERING, use_bias=False ,padding='same')(o)
    
        pool_outs.append( o )
    
        #if p==2:
        #    visualFeature=raw    
   
  

    o = Concatenate( axis=3)(pool_outs )
    
	# ���
    o = Conv2D(32, (3,3), data_format=IMAGE_ORDERING, use_bias=False ,padding='same')(o)
    #visualFeature=o
    o = BatchNormalization()(o)
    
    o = Activation('relu' )(o)


    up1 = Conv2DTranspose(32, (2, 2), strides=(2, 2),  padding='same')(o)
    up1 = Conv2D(32, 3,  padding='same')(up1)

    up2 = Conv2DTranspose(32, (2, 2), strides=(2, 2),padding='same')(up1)
    oto2=UpSampling2D(4)(o)
    up2=Concatenate( axis=3)([oto2,up2] )
    up2 = Conv2D(32, 3,  padding='same')(up2)

    up3 = Conv2DTranspose(32, (2, 2), strides=(2, 2),  padding='same')(up2)
    oto3=UpSampling2D(8)(o)    
    up1to3=UpSampling2D(4)(up1)
    up3 = Concatenate( axis=3)([oto3,up1to3,up3] )

    up3 = Conv2D(32, 3,  padding='same')(up3)


    


    out = Conv2D( classNum,(1,1),data_format=IMAGE_ORDERING, padding='same' )(up3)

    
    return out
